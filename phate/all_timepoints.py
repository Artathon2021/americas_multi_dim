# -*- coding: utf-8 -*-
"""all_timepoints.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xp-aFFZfO6F7X_QTZOKWIu018h9J56T_

## Testing Levenshtein distance and PHATE on tsv files
1. Pull tsv data into your favorite dataframe
2. Run through Lev distance to get adjacency matrix
3. <s>Combine adjacency matrix and original dataframe</s> No need, PHATE can take just the matrix
4. Pass to PHATE
"""

# Install necessary packages into the Google Collab notebook
!pip install python-Levenshtein
!pip install phate

# Importing favorite packages
from Levenshtein import ratio, distance # https://rawgit.com/ztane/python-Levenshtein/master/docs/Levenshtein.html#Levenshtein-ratio
import phate
import pandas as pd
import numpy as np 
import os

"""

---


### Grabbing Data"""

from google.colab import drive
drive.mount('/content/drive')

# Peek to see if file is there
file_paths = ["/content/drive/MyDrive/Team 1/Covid_Vaccine_6fbca1da-1a25-4848-ae35-eaffc6bb392b/IHCV2020-020.IHCV2020-020-Spikepos-Mem-B-1TP.pooled.tsv", 
              "/content/drive/MyDrive/Team 1/Covid_Vaccine_6fbca1da-1a25-4848-ae35-eaffc6bb392b/IHCV2020-020.IHCV2020-020-Spikepos-Mem-B-2TP.pooled.tsv", 
              "/content/drive/MyDrive/Team 1/Covid_Vaccine_6fbca1da-1a25-4848-ae35-eaffc6bb392b/IHCV2020-020.IHCV2020-020-Spikepos-Mem-B-4TP.pooled.tsv"]
for file in file_paths : assert os.path.isfile(file), "File {} doesn't exist or isn't readable".format(file)

# Combine data across tsvs's 
frames = [] 

for file in file_paths : 
  frames.append(pd.read_csv(file, sep = '\t'))

# Adding timepoint markers to files
timepoints = [1, 2, 4]
for i in range(len(frames)) : 
  frames[i]['timepoint'] = timepoints[i]

data = pd.concat(frames)

# Take a peek at our loaded data
data.head()

"""

---


### Creating Adjacency Matrix using Edit-Distance"""

# Simple loop through cdr3_aa to create distances

# Make our adj matrix first
num_clones = len(data.index)
print("Using", num_clones, "rows")
adj_matrix = np.zeros((num_clones, num_clones))

# Make a simple reference list of sequences instead of having to access the dataframe
seqs = data.loc[:,'cdr3_aa'].values

import time
start = time.time()
for i in range(num_clones) : 
  for j in range(num_clones) : 
    # adj_matrix[i][j] = max(0, (ratio(seqs[i], seqs[j])-0.45)**2) # by thresholded + stretched levenshtein "ratio"/similarity
    adj_matrix[i][j] = distance(seqs[i], seqs[j]) # by levenshtein "ratio"/similarity
    # if adj_matrix[i][j] != 0.0 : adj_matrix[i][j] += 0.5
    # adj_matrix[i][j] = distance(seqs[i], seqs[j]) # by levenshtein distance
print("Took", time.time()-start, "seconds")

# Take a peek at the adj matrix
adj_matrix

"""

---
### Test PHATE
"""

phate_operator = phate.PHATE(knn=15, decay=20, t=150, knn_dist='precomputed')
Y_phate = phate_operator.fit_transform(adj_matrix)

# Take a peek at the coords
import matplotlib.pyplot as plt
plt.scatter(Y_phate[:,0], Y_phate[:,1])

# Save our coords along with all the data
data['phate1'] = Y_phate[:,0]
data['phate2'] = Y_phate[:,1]

data.to_csv("all_timepoints_phate.tsv", sep="\t", index=False)

# RUN MANY PHATE FITS FOR DIFFERENT PARAMETERS
# Going to change the timesteps for the diffusion operator
possible_t = [10*n for n in range(1, 16)]

for test_t in possible_t : 
  phate_operator = phate.PHATE(knn=15, decay=20, t=test_t, knn_dist='precomputed')
  Y_phate = phate_operator.fit_transform(adj_matrix)
  data['phate_x_' + str(test_t)] = Y_phate[:,0]
  data['phate_y_' + str(test_t)] = Y_phate[:,1]

data.to_csv("all_timepoints_multi_phate.tsv", sep="\t", index=False)

data.head() # Double check

plt.hist(adj_matrix.flatten(), 25)

plt.imshow(adj_matrix, cmap='hot', interpolation='nearest')
plt.show()

# Cdr3 length distribution 
plt.hist([len(i) for i in seqs])

"""PHATE graph probably looks as expected, with similarities in strings"""
